---
title: 应对大规模流量
sidebarTitle: 应对大规模流量
keywords: ["high volume", "capacity handling", "stream capacity", "volume management", "high throughput", "scaling stream"]
---

---

<div id="how-to-plan-for-high-volume-social-data-events">
  ### 如何规划高流量社交数据事件
</div>

重大全国性和全球性事件往往会伴随着社交媒体平台上用户活动量的剧烈飙升。有些事件是可以提前预知的，比如超级碗、政治选举以及全球各地的新年庆祝活动。另一些情况下，流量激增则源于突发事件，例如自然灾害、突发政治事件、流行文化热点时刻，或类似 COVID-19 这样的公共卫生大流行。

这些用户活动的激增有时可能非常短暂（以秒计），也可能会持续数分钟之久。无论其起因如何，都需要认真考虑它们对使用 X 数据的应用所产生的影响。以下是一些最佳实践，可帮助你的团队为高流量社交数据事件做好准备。

<div id="review-your-current-filtered-stream-rules">
  #### 审查你当前的 filtered stream 规则
</div>

* 某些关键词在高数据量事件期间可能会急剧增加，例如品牌赞助大型体育赛事时与该品牌相关的提及量。
* 谨慎避免任何不必要或过于宽泛的规则，以免产生不必要的活动量。
* 在已知将出现高数据量的事件之前，考虑提前与客户沟通，帮助他们做好相应规划。
     

<div id="stress-test-your-application">
  #### 对你的应用进行压力测试
</div>

预估突发数据量可能达到日常平均消耗量的 5–10 倍。根据你的规则集，增幅可能会更高。

<div id="understand-delivery-caps-for-connections">
  #### 了解连接的投递上限
</div>

流式连接的吞吐量和投递上限是根据访问级别设定的。这会导致每个流中可投递结果的数量为固定值。

* **Academic**：250 帖子/秒
* **Enterprise**：帖子/秒由访问级别决定

<div id="optimize-to-stay-connected">
  #### 优化以保持持续连接
</div>

在使用流时，保持持续连接对于避免数据丢失至关重要。你的客户端应用程序应能够检测到断线，并在断开后立即尝试重新连接；如果重连尝试失败，则应使用指数退避策略进行重试。
 

<div id="add-built-in-buffering-on-your-end">
  #### 在你这端添加内置缓冲机制
</div>

构建多线程应用是处理大规模流数据的关键策略。从总体上看，管理数据流的最佳实践是使用一个单独的线程/进程来建立流式连接，然后将接收到的 JSON 活动数据写入内存结构或带缓冲的流读取器中。这个“轻量级”的流处理线程负责处理传入数据，这些数据可以缓存在内存中，并根据需要扩展或收缩。然后由另一个线程来消费该哈希表，完成解析 JSON、准备数据库写入，或你的应用需要执行的其他繁重处理工作。
 

<div id="global-events-global-time-zones">
  #### 全球性事件 = 全球时区
</div>

这些事件可能发生在正常工作时间以外或周末，因此请确保你的团队已做好准备，应对在常规工作时间之外出现的流量高峰。