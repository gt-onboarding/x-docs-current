---
title: 消费流式数据
sidebarTitle: 消费流式数据
keywords: ["消费流式数据", "流式数据", "处理流", "处理流式数据", "流处理", "流消费"]
---

<div id="building-a-client-to-consume-streaming-data">
  ### 构建用于处理流式数据的客户端
</div>

在使用流式端点时，有一些通用的最佳实践可以帮助你提升使用效率。  
 

<div id="client-design">
  #### Client 设计
</div>

在使用 filter stream 端点构建解决方案时，你需要一个能够执行以下操作的 client：

1. 建立到 filter stream 端点的 HTTPS 流式连接。
2. 以异步方式向 filter stream rules 端点发送 POST 请求，从流中添加和删除规则。
3. 处理低数据量场景 – 维护流式连接，检测 Post 对象和 keep-alive 信号。
4. 处理高数据量场景 – 使用异步进程将流数据摄取与后续处理解耦，并确保客户端缓冲区定期刷新。
5. 在客户端管理数据量用量/消耗的跟踪。
6. 检测流断开，评估情况并自动重新连接到流。
    

<div id="connecting-to-a-streaming-endpoint">
  #### 连接到流式端点
</div>

与 X API v2 流式端点建立连接意味着发起一个存活时间非常长的 HTTP 请求，并以增量方式解析响应。从概念上讲，你可以将其看作通过 HTTP 下载一个无限长的文件。一旦连接建立，只要连接保持打开，X 服务器就会通过该连接持续发送 Post 事件。
 

<div id="consuming-data">
  #### 消费数据
</div>

请注意，JSON 对象的各个字段是无序的，并且在任何情况下都不保证所有字段都会出现。同样，各个活动（activity）不会按排序后的顺序交付，并且可能会遇到重复消息。请记住，随着时间的推移，新的消息类型可能会被添加并通过流发送。

因此，你的客户端必须能够处理：

* 字段以任意顺序出现
* 意外出现或缺失的字段
* 未排序的帖子
* 重复消息
* 在任意时间通过流传来的新的、任意类型的消息

除了相关的帖子数据和请求的字段参数外，通过流连接还可能传递以下类型的消息。请注意，此列表可能并不完整——流中可能会引入其他对象。请确保你的解析器对意外的消息格式具有足够的容错性。
 

<div id="buffering">
  #### 缓冲
</div>

流式端点会在数据一旦可用时就尽快发送给你，在很多情况下这会带来很高的数据量。如果 X 服务器暂时无法立即向流中写入新数据（例如你的客户端读取速度不够快，更多信息参见[处理断开连接](/zh/x-api/posts/filtered-stream#what-is-a-disconnection)），它会在自身一端对内容进行缓冲，让你的客户端有机会赶上进度。然而，当该缓冲区被填满时，会强制发起断开以关闭连接，缓冲的帖子会被丢弃且不会重发。更多详情见下文。

识别应用处理滞后的一种方法，是比较接收到的帖子时间戳与当前时间，并在一段时间内持续追踪这个差值。

尽管由于公网上潜在的延迟和短暂抖动，流的积压情况永远无法被完全消除，但通过正确配置你的应用，可以在很大程度上避免它们。要尽量减少这种积压的发生：

* 确保你的客户端读取流的速度足够快。通常在读取流时不应做任何实质性的处理工作。读取流后，将这些活动交给另一个线程/进程/数据存储，异步地执行处理。
* 确保你的数据中心具有足够的入站带宽，既能满足大规模的持续数据量，也能应对明显更大的峰值（例如正常流量的 5–10 倍）。对于 filtered stream，你这一端的数据量和相应所需带宽完全取决于你的规则匹配到哪些帖子。
   

<div id="usage-tracking-and-rule-management">
  #### 使用情况跟踪和规则管理
</div>

由于各个开发者对其流的“正常”数据量应当是什么样有不同预期，我们无法就具体的百分比增减或时间周期给出通用建议。 

请考虑监控你的流数据量，关注是否出现异常偏差。数据量下降可能与流断开属于不同类型的问题。在这种情况下，流仍然会接收到保活信号，并且很可能还能收到部分新的活动数据。不过，如果收到的帖子数量明显减少，你就应该调查是否有任何原因导致你的应用或网络的入站数据量下降，并检查 [状态页面](https://api.twitterstat.us/) 上是否有相关公告。

要实现这类监控，你可以跟踪在一段固定时间内预期看到的新帖子数量。如果某个流的数据量显著低于指定阈值，并且在设定时间内未恢复，则应该触发告警和通知。你也可能需要监控数据量的大幅增加，尤其是在你正在修改 filtered stream 中的规则，或者发生导致帖子活动激增的事件时。

需要特别注意的是，通过 filtered stream 传送的帖子会计入每月帖子总量，你应该对使用量进行跟踪和调整，以实现优化。如果流量较高，可以考虑在每条规则中添加 `sample:` 运算符，将匹配率从 100% 降低到 `sample:50`，或在必要时降到 `sample:25`。

此外，我们鼓励你在应用中实现相关机制，当数据量超过预设阈值时向团队发出告警，并在必要时引入其他措施，例如自动删除带来过多数据的规则，或者在极端情况下完全断开与流的连接。
 

<div id="responding-to-system-messages">
  #### 响应系统消息
</div>

保活信号
流会至少每 20 秒通过已打开的连接发送一个保活信号（keep-alive signal），或称心跳（heartbeat），其形式是一个 \r\n 回车符，以防止你的客户端发生超时。你的客户端应用应当能够容忍流中的 \r\n 字符。

如果你的客户端在 HTTP 库上正确实现了读取超时（read timeout），你的应用就可以依赖 HTTP 协议和 HTTP 库，在此时间窗口内未读取到任何数据时触发事件，而无需显式监控 \r\n 字符。

这个事件通常会是抛出一个异常，或根据所使用的 HTTP 库触发其他事件。强烈建议使用错误/事件处理程序包装你的 HTTP 方法，以检测这些超时情况。发生超时时，你的应用应尝试重新连接。

错误消息
v2 流式端点也可能在流中返回错误消息。下面提供了这些消息的基本格式以及一些示例。请注意，返回的消息可能会发生变化，并引入新的消息。客户端应用需要能够容忍系统消息负载的变化。

请注意，错误消息会链接到说明如何解决该问题的相关文档。

消息格式：

```{
	"errors": [{
		"title": "operational-disconnect",
		"disconnect_type": "UpstreamOperationalDisconnect",
		"detail": "此流已因运营原因在上游断开连接。",
		"type": "https://api.x.com/2/problems/operational-disconnect"
	}]
}
```

请注意，如果导致强制断开的数据堆积本身阻止了错误消息发送出去，那么指示由于缓冲区已满而进行强制断开的错误消息可能永远无法到达你的客户端。因此，你的应用不应依赖这些消息来发起重连。
