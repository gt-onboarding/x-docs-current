---
title: 消费流式数据
sidebarTitle: 消费流式数据
keywords: ["消费流式数据", "流式数据", "处理数据流", "处理流式数据", "流处理", "流式数据消费"]
---

<div id="building-a-client-to-consume-streaming-data">
  ### 构建用于消费流式数据的客户端
</div>

在使用流式端点时，有一些通用的最佳实践可以帮助你优化使用方式和性能。  
 

<div id="client-design">
  #### 客户端设计
</div>

在使用 filter stream endpoint 构建解决方案时，你需要一个能够完成以下操作的客户端：

1. 与 filter stream endpoint 建立 HTTPS 流式连接。
2. 以异步方式向 filter stream rules endpoint 发送 POST 请求，在流中添加和删除规则。
3. 处理低数据量流量——维护流式连接，检测 Post 对象和 keep-alive 信号。
4. 处理高数据量流量——使用异步进程将流数据接入与后续处理解耦，并确保客户端缓冲区定期刷新。
5. 在客户端跟踪并管理用量消耗。
6. 检测流断开、评估原因并自动重新连接到流。
    

<div id="connecting-to-a-streaming-endpoint">
  #### 连接到流式端点
</div>

与 X API v2 流式端点建立连接意味着发起一个存活时间非常长的 HTTP 请求，并以增量方式解析响应。从概念上讲，你可以将其视为通过 HTTP 下载一个无限长的文件。一旦建立连接，只要连接保持打开状态，X 服务器就会通过该连接持续发送 Post 事件。
 

<div id="consuming-data">
  #### 消费数据
</div>

请注意，JSON 对象中的各个字段没有固定顺序，并且在不同情况下并不一定都会包含所有字段。同样，单条活动消息的传递也不是按排序顺序进行的，并且你可能会遇到重复消息。还要记住，随着时间推移，新的消息类型可能会被添加并通过流发送。

因此，你的客户端必须能够处理：

* 字段以任意顺序出现
* 意外出现或缺失的字段
* 未排序的帖子
* 重复的消息
* 随时可能出现在流中的新的任意消息类型

除了相关的帖子数据以及你请求的字段参数之外，通过流连接还可能传递以下类型的消息。请注意，此列表可能并不完整——流中可能会引入其他对象。请确保你的解析器能够处理意外的消息格式。
 

<div id="buffering">
  #### 缓冲
</div>

流式端点会在数据一旦可用时就尽快发送给你，在很多情况下这会导致数据量非常大。如果 X 服务器端无法立即向流中写入新数据（例如，如果你的客户端读取速度不够快，更多信息参见[处理断连](/zh/x-api/posts/filtered-stream#what-is-a-disconnection)），它会在服务器端对内容进行缓冲，以便让你的客户端有时间赶上。不过，当该缓冲区被占满时，就会发起强制断开以中断连接，缓冲的帖子将被丢弃且不会重发。更多详情见下文。

识别你的应用何时出现处理滞后的一个方法，是比较接收到的帖子的时间戳与当前时间，并随时间跟踪这一差异。

虽然由于公共互联网上的潜在延迟和小故障，流数据积压永远无法被完全消除，但通过对你的应用进行合理配置，可以在很大程度上避免它们。要尽量减少这类积压的发生：

* 确保你的客户端以足够快的速度读取流。通常在读取流时不应做任何实际的处理工作。读取流之后，将要处理的内容交给其他线程/进程/数据存储，异步执行处理。
* 确保你的数据中心具有足够的入站带宽，既能处理大规模的持续数据量，也能应对大幅度更高的流量峰值（例如正常流量的 5-10 倍）。对于 filtered stream，你这端所需的数据量和相应带宽完全取决于你的规则匹配到了哪些帖子。
   

<div id="usage-tracking-and-rule-management">
  #### 使用情况跟踪和规则管理
</div>

由于开发者对其流的“正常”数据量有不同的预期，我们无法就具体的百分比增减或时间段给出通用建议。 

建议监控你的流数据量，以便发现是否存在异常波动。数据量的减少可能意味着与流断开连接不同的问题。在这种情况下，流仍然会接收保活信号，并且通常仍然会接收到一些新的活动数据。然而，如果帖子数量显著减少，你就应该调查是否有任何原因导致传入到你应用或网络的数据量下降，并检查[状态页面](https://api.twitterstat.us/)是否有任何相关公告。

要实现此类监控，你可以跟踪在一段设定时间内你预期会看到的新帖子数量。如果某个流的数据量远低于指定阈值，并且在设定时间内没有恢复，则应触发警报和通知。如果你正在调整 filtered stream 中的规则，或者发生了导致帖子活动量激增的事件，你也可能需要监控数据量的大幅增加。

需要注意的是，通过 filtered stream 传递的帖子会计入每月帖子总量，你应当跟踪并调整使用量以实现优化。如果数据量较高，请考虑在每条规则中添加 `sample:` 运算符，将匹配比例从 100% 降低到 `sample:50` 或 `sample:25`（在必要时）。

此外，我们建议你在应用中实现相关措施，当数据量超过预设阈值时提醒你的团队，并视情况引入其他措施，例如自动删除带来过多数据的规则，或在极端情况下完全断开与流的连接。
 

<div id="responding-to-system-messages">
  #### 响应系统消息
</div>

保持连接信号
至少每隔 20 秒，流会通过已打开的连接发送一个保持连接信号（keep-alive signal）或心跳（heartbeat），形式是一个 `\r\n` 回车符，以防止客户端超时。你的客户端应用应当能够容忍流中的 `\r\n` 字符。

如果你的客户端在所使用的 HTTP 库中正确实现了读取超时，你的应用就可以依赖 HTTP 协议和 HTTP 库，在在该时间段内没有读取到任何数据时触发事件，而无需显式监控 `\r\n` 字符。

该事件通常表现为抛出一个异常，或者根据所使用的 HTTP 库触发其他类型的事件。强烈建议为你的 HTTP 方法添加错误 / 事件处理器来检测这些超时情况。当发生超时时，你的应用应尝试重新连接。

错误消息
v2 流式端点也可能在流中返回错误消息。下面给出了这些消息的基本格式以及一些示例。请注意，返回的消息可能会发生变化，并可能引入新的消息。客户端应用需要能够适应系统消息负载的变化。

请注意，错误消息会包含指向文档的链接，文档中会说明如何解决该问题。

消息格式：

```{
	"errors": [{
		"title": "operational-disconnect",
		"disconnect_type": "UpstreamOperationalDisconnect",
		"detail": "此流已因运营原因在上游断开连接。",
		"type": "https://api.x.com/2/problems/operational-disconnect"
	}]
}
```

请注意，如果导致强制断开连接的缓冲区积压本身阻止错误消息发送成功，那么指示因缓冲区已满而被强制断开连接的错误消息可能永远不会到达你的客户端。因此，你的应用不应依赖这些消息来发起重新连接。
